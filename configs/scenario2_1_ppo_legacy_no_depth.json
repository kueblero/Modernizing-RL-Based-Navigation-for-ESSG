{
  "name": "Scenario 2.1: PPO + Legacy Actions (16 discrete) - No Depth",
  "seed": 42,
  "strict_determinism": false,
  "agent": {
    "name": "ppo",
    "blocks": 1000,
    "alpha": 0.0001,
    "gamma": 0.99,
    "entropy_coef": 0.05,
    "value_coef": 0.5,
    "num_steps": 60,
    "ppo_epochs": 4,
    "clip_epsilon": 0.25,
    "use_gae": true,
    "gae_lambda": 0.9,
    "max_grad_norm": 0.5,
    "clip_value": true,
    "clip_value_epsilon": 0.2,
    "target_kl": 0.01,
    "collision_loss_coef": 0.2,
    "use_torch_compile": true,
    "use_trajectory_info": true,
    "trajectory_chunk_size": 300,
    "auto_trajectory_chunk": false,
    "trajectory_chunk_min": 100,
    "trajectory_chunk_max": 300,
    "trajectory_chunk_backoff": 1.0
  },
  "navigation": {
    "rgb_dim": 512,
    "depth_dim": 256,
    "use_depth": false,
    "action_dim": 64,
    "sg_dim": 512,
    "policy_hidden": 1024,
    "use_transformer": false,
    "max_object_types": 5000,
    "max_relation_types": 100
  },
  "env": {
    "render": false,
    "rho": 0.001,
    "max_actions": 40,
    "use_legacy_actions": true,
    "curriculum_stage": null,
    "stop_stagnation_steps": 5,
    "stop_stagnation_bonus": 0.05
  },
  "training": {
    "num_agents": 32,
    "eval_interval": 100,
    "save_interval": 9999,
    "il_pretrain": false,
    "notes": "PPO baseline with 16 legacy actions. No IL pre-training, no curriculum, no depth input."
  },
    "evaluation": {
    "enabled": true,
    "eval_interval": 50,
    "eval_scene_numbers": [28, 29, 30],
    "episodes_per_scene": 10
  }
}
